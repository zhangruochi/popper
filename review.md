# ICML 审稿意见

## 总体评价

本文提出一个用于肽类先导优化（peptide lead optimization）的**Pareto 指导、多智能体、工具约束（numeric governance）**框架：LLM 作为"有界编排器"，在 Insight/Design/Evaluation 三个模式间路由；所有数值结论来自外部工具；用可解释的 SAR 规则挖掘作为外部记忆；用 Pareto（NSGA-II 风格的非支配排序+拥挤度）做多轮父代选择；并用结构化 reflection JSON 做策略更新与探索/利用调节。论文写作整体专业，问题设置合理，系统动机与工程细节较完整，属于"方法+系统"型工作。

若以 ICML 标准衡量，我认为这篇论文的主要风险在于：**算法新颖性更多体现在组合与工程化约束治理**，而不是在核心优化理论/学习算法上的突破；以及**实验对比与消融的因果归因仍不够严密**（特别是 LLM 与工具、规则挖掘与 Pareto 选择各自贡献的隔离与统计显著性说明）。

---

## 贡献与总结（我对论文的理解）

- **问题**：弱反馈、噪声、缺失、多目标、预算受限的多轮肽优化。
- **方法**：
  - 三模式代理：Insight（SAR/规则挖掘/可选训练 tabular 模型+SHAP）、Design（候选生成+多轮优化）、Evaluation（外部评估）。
  - **SAR 规则挖掘**：从成对突变提取规则及 amplification factor，做加性/相容性检验建图，通过 clique / transitive / subtraction 三策略生成候选，并保留证据链。
  - **分层打分**：将 potency/structure/dev 三类指标映射到 $[0,1]$ 并加权，再用软约束罚项；缺失值用确定性默认值填补。
  - **Pareto 选择**：非支配排序+拥挤距离；失败时回退到标量分数 TopK。
  - **Reflection**：输出结构化 JSON（包含 validated/failed hypotheses、策略、exploration ratio），失败则用基于改进幅度的确定性回退。
- **实验**：Scenario A（稀疏 SAR）与 B（富 SAR），以及 case study（环肽 KRpep-2d）。指标包括 final score、SAR violation、约束满足率、结构/能量等。

---

## 优点（Strengths）

1. **问题契合真实场景**：强调弱/缺失反馈、昂贵评估与多目标权衡，符合药物/肽优化的实际痛点。
2. **"数值治理"立场清晰**：将定量输出交给工具/预言机，LLM 负责有界编排与解释，能减少"幻觉数值"的风险，提升可审计性。
3. **可解释性设计较到位**：SAR 规则、相容性图、证据链、结构化反思产物，这些都对 human-in-the-loop 有价值。
4. **多目标处理合理**：Pareto 前沿与拥挤距离用于父代选择比简单标量化更稳健；并提供回退机制。
5. **系统写作完成度高**：形式化定义、算法描述、指标与图表组织较完整，读者能复现整体思路（但见下方可复现性细节问题）。

---

## 主要问题（Weaknesses / Concerns）

### 1. 新颖性边界不够清晰

多智能体编排 + NSGA-II 组件 + 规则挖掘 + 反思/自适应探索 的组合是合理的工程方案，但论文需要更明确回答：

- 与已有"LLM+工具"的科学代理、以及已有多目标优化（NSGA-II/BO/AL）在肽设计上的工作相比，**核心方法学增量**是什么？是"数值治理+可审计反思闭环"的系统化范式，还是某个关键算法模块（如规则相容性图与 clique/transitive/subtraction 的生成策略）带来本质提升？

### 2. 实验对比的公平性与强基线不足

- 文中把 RFD+MPNN、PepMLM、NSGA-II、单轮 GPT 作为基线，但缺少更强或更贴近设定的基线：例如**带约束/缺失值处理的多目标 BO**、**带预算的多目标主动学习**、或**同样多轮但不使用 LLM 的策略**（例如纯规则+Pareto 的迭代、或纯模型引导的局部搜索）。
- 对 LLM 相关部分，缺少"同样多轮、同样工具调用，但不使用 reflection/不使用 SAR 证据注入"的严格对照，以分离"多轮本身"与"反思策略更新"的贡献。

### 3. "缺失值默认填补"可能引入系统性偏置

例如结构默认值 $u_{\text{backbone}}^{default}=0.7$ 偏乐观，会改变 Pareto 排序与 selection pressure。需要更系统的敏感性分析（默认值/权重/罚项系数变化下的稳健性）。

### 4. 标量 final_score 与 Pareto 目标耦合关系不够透明

- 父代选择用 Pareto（pot/struct/dev），停止与反思却用标量 $s(x)$。这在工程上合理，但可能导致优化目标"隐式切换"。建议说明何时 Pareto 与标量冲突、以及对结果的影响（例如 hypervolume 可能提升但 final_score 不变，或反之）。

### 5. 统计显著性与方差来源

- 文中提到 5 seeds、p 值，但需要更清楚：随机性来自哪里（LLM 采样、候选生成、模型训练、评估噪声）？paired t-test 的配对对象是什么？是否满足独立同分布假设？

### 6. 可复现性风险

- 若结构/能量 oracle 依赖"远程计算"或特定版本工具，ICML 通常要求更明确的可复现路径：工具版本、调用参数、失败重试、缓存策略、以及数据/脚本公开计划。

---

## 需要作者澄清的问题（Questions for the Authors）

1. **规则挖掘细节**：amplification factor 的定义依赖 $f(x)$ 的选择。对于不同 assay（IC50/Kd 等）、不同噪声水平，你们如何保证规则的稳健性？阈值 $\alpha_{th}$、容忍度 $\tau$ 的选择依据是什么？

2. **相容性图与 clique 搜索的复杂度**：最坏情况下 clique 枚举可能很贵。实际中如何限制？是否做了上界剪枝或按证据强度排序截断？

3. **反思 JSON 的可靠性**：解析失败率是多少？失败时回退策略在最终性能中占比多少？如果反思输出与数值证据冲突（例如提出"某突变有益"但数据不支持），如何处理？

4. **约束满足与"后过滤"**：你们的方法有生成前的硬约束检查；基线是否也允许同等约束过滤？否则可能会把"约束治理"优势与"生成质量"混在一起。

5. **评价指标**：final_score 的权重（0.2/0.6/0.2）与罚项系数是否对所有数据集固定？如果固定，是否对某些任务不公平？如果调参，是否会产生任务泄漏？

---

## 建议的改进（Actionable Suggestions）

1. **补强基线**：加入至少一个"强而公平"的多目标预算方法（如多目标 BO/AL 或带约束的演化/局部搜索变体），并保证相同的 oracle 预算与约束过滤。

2. **更细粒度消融**：建议至少包含：
   - 仅 Pareto（无规则、无 LLM）
   - 仅规则+Pareto（无 LLM）
   - LLM 多轮但无规则注入
   - LLM 多轮但无 reflection
   - 自适应 exploration ratio vs 固定比例

3. **敏感性与稳健性分析**：对缺失值默认填补、权重与罚项系数做网格或扰动分析；报告超参变化下的排名稳定性与方差。

4. **复现清单**：提供一个明确的"最小可复现实验路径"（含固定种子、工具版本、缓存、以及在无远程 oracle 时的替代设置），并公开关键中间产物格式（你们已经用了 JSON artifact，这是优势）。

5. **更明确的"方法学主张"**：在引言/贡献中更清楚区分：你们的核心贡献是一个可审计的 agentic 设计范式，还是一个特定的新型 SAR 规则组合生成算法；并在实验中对应验证该主张。

---

## 评分（ICML风格，供参考）

- **总体评分**：6/10（Weak Accept）  
  理由：系统整合扎实、问题重要、结果看起来有提升；但新颖性与严格性（基线、公平性、敏感性、复现）仍需加强才能达到更稳的接受线。

- **新颖性**：5/10  
- **技术质量**：6/10  
- **实验质量**：6/10（需补强基线/消融与稳健性）  
- **写作清晰度**：8/10  
- **可复现性**：5/10（目前信息不够"可落地复现"）

---

## 结论

这是一篇面向真实肽类优化流程的"可审计、多目标、多轮代理系统"工作，整体完成度较高，也有不错的可解释性与工程治理意识。但若要更符合 ICML 对方法学与实验严谨性的期望，作者需要在**强基线、公平对比、敏感性分析与可复现细节**方面补齐证据链，并更清晰界定本文的核心新颖性与不可替代贡献。
